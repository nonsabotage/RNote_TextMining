---
title: "Ch02 整理データを使ったセンチメント分析"
output:
    html_document:
        toc: true
        toc_float: true
        highlight: tango
        theme: flatly
        css: mycss.css
        code_folding: show
        include:
            - in_header: in_head.html
        df_print: "paged"

---

人が文章を読むとき, 人は言葉が持つ感情的な
意図について, ポジティブなものかネガティブなものなのか,
驚きとか嫌悪感といったもっと微妙な意味愛を持つ言葉で
表現すべきものかといったことを推論します.

センチメント分析の方法の１つは,
テキストを個別の単語の組み合わせと考えて,
テキスト全体の感情内容は個別の単語の感情内容の総和と
考えるものである.

# ライブラリー

```{r setup, message=FALSE}

# load libs
libs <- c( "tidyverse", "tidytext", 
           "janeaustenr", "gutenbergr", "scales", 
           "wordcloud")
for( lib in libs ) {
    if(!require(lib, character.only = TRUE)) {
        install.packages(lib)
        library(lib, character.only = TRUE)
    }
}

```


# データセット

テキストに含まれる意見や感情を評価するための方法や辞書には
さまざまなものがある.
`sentiments`データセットには複数の
センチメント辞書が含まれている.

```{r .numberLines}
sentiments %>% head()
```

ここで使われてる辞書はいずれもユニグラム,
つまり単語をぶ分類の単位としている. それぞれの辞書を確認する.
どのように単語を評価しているのかは, 辞書ごとに異なることがわかる.
・・・とは言ったものの, 結局のところ数値に変換してしまうのではないだろうか?

```{r}
dict_name <- c("afinn", "bing", "nrc")
map( dict_name,  ~ head(get_sentiments(.x)) ) %>%
  walk( ~ print(.x))
```


# 内部結合を使ったセンチメント分析

```{r}
tidy_books <-
  austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(
      str_detect(
        text,
        regex("^chapter [0-9]{1,2}", ignore_case =TRUE)
      )
    )
  ) %>%
  ungroup() %>%
  unnest_tokens(word, text)
tidy_books %>% tail()
```


```{r}
# 辞書を使って喜びの単語を取り出す
nrcjoy <-
  get_sentiments("nrc") %>%
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrcjoy, by = "word") %>%
  count(word, sort = TRUE)
```

ネガティブな単語とポジティブな単語を
別の列に分けて,
センチメント量(Positive - negative)を求める.

```{r}
janeaustensentiment <-
  tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  # 80で割ったときの商でデータを分類
  count(book, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

janeaustensentiment %>% head()
```

このデータを使うことで, 各作品の流れに沿って
センチメントスコアがどのように変化しているかを
プロットすることができる.

```{r}
janeaustensentiment %>%
  ggplot(aes(index, sentiment, fill = book)) +
  geom_col(show.legend = TRUE) +
  facet_wrap( ~ book, ncol = 2, scales = "free_x") +
  theme_light()
```


# 3つのセンチメント辞書の比較


辞書を全部使って『高慢と偏見』の筋に沿って
感情がどのように変化しているかを調べる

```{r}
pride_prejudice <-
  tidy_books %>%
  filter(book == "Pride & Prejudice")

pride_prejudice %>% head()
```


```{r}

# afinnはスコアなので別途計算
afinn <-
  pride_prejudice %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(index = linenumber %/% 80) %>%
  summarise(sentiment = sum(score)) %>%
  mutate(method = "AFINN")

# bing, nrcは２値分類されているのでそれを使う
bing_and_nrc <- bind_rows(
  pride_prejudice %>%
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>%
    inner_join(get_sentiments("nrc") %>%
               filter(sentiment %in% c("positive", "negative"))) %>%
    mutate(method = "NRC")
) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

# 3つをまとめる
bind_rows ( afinn, bing_and_nrc ) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = TRUE) +
  facet_wrap( ~ method, ncol = 1) +
  theme_light() +
  scale_fill_viridis_d()



```

小説の同じような場面で, 感情の起伏があるのがわかるが,
その程度は大きく異なるのが見て取れる.
AFINNはポジティブ, ネガティブの振れ幅が大きい.
Bing辞書は緩徐の絶対値が小さく, ポジティブな単語やネガティブな
感情はつづく. NRCではポジティブな感情に傾いていることがわかる.

ポジティブな感情とネガティブな感情のトークン数を数える
```{r}
get_sentiments("nrc") %>%
  filter(sentiment %in% c("positive", "negative")) %>%
  count(sentiment)
```


```{r}
get_sentiments("bing") %>%
  count(sentiment)
```

結局, どのような辞書を使うかによって,
**センチメント量は異なる**ということを認識しておく必要がある.

# ポジティブ、ネガティブ

```{r}
bing_word_counts <-
  tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()



bing_word_counts %>% head()

```

```{r}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = F) +
  facet_wrap ( ~ sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment", x  = NULL) +
  coord_flip() +
  theme_classic()
```


# ワードクラウド

```{r}
tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(
    wordcloud(word, n, max.words = 100)
  )
```


より詳しい分析を行うには
関数がある. その際には, `reshape2::acast`を活用して, 
一度マトリックスに変換する必要がある. 
なお以下の図は単語の文字サイズでどちらの
感情が多いかを比較できないことに注意する. 

```{r}
tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(
    colors = c("gray20", "gray80"), 
    max.words = 100
  )
```


# 単語を超えた単位

センテンスをトークンにして, 分析することも重要である. 


```{r}
PandP_sentences <-
    data_frame(
      text = prideprejudice
    ) %>%
    unnest_tokens(sentence, text, token = "sentences")
```


実はUTF8よりもASCIIの方が良い変換をするなど, 
エンコーディングが情報を持つ場合もある. 
unnest_tokens()は正規表現を使ったトークン化も可能である. 
例えば小説を章単位に区切ってデータフレームを
作成することができる.. 

```{r}
austen_chapters <-
  austen_books() %>%
  group_by(book) %>%
  unnest_tokens(
    chapter, 
    text, 
    token = "regex", 
    pattern = "Chapter|CHAPTER [\\dIVXLC]"
  ) %>%
  ungroup()

austen_chapters %>%
  group_by(book) %>%
  summarise(chapters = n())
```


このデータフレームを使うことで
「ジェーン・オースティン」の各小説で最も
ネガティブな章はどれか」というような問いに
答えることができる. 


```{r}
bingnegative <-
  get_sentiments("bing") %>%
  filter(sentiment =="negative")

wordcounts <- 
  tidy_books %>%
  group_by(book, chapter) %>%
  summarise(words = n())

tidy_books %>%
  semi_join(bingnegative) %>%
  group_by(book, chapter) %>%
  summarise(negativewords = n()) %>%
  left_join(wordcounts, by = c("book", "chapter")) %>%
  mutate(ratio = negativewords / words) %>%
  filter(chapter != 0) %>%
  top_n(1) %>%
  ungroup()

```










































































